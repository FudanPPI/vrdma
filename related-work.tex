\section{Related Work}

Traditional TCP/IP is the basic network for each user in clouds. There are lots of software solutions for traditional network virtualization. For VMs and containers, there are lots of vNICs (virtual network interface cards), e.g. virtio-net~\cite{virtio-russell2008}, vhost-net~\cite{vhost-net},  vhost-user-net~\cite{vhost-user-net} for VMs and veth~\cite{veth} for containers. The vNICs are in different space in host. Then, software virtual switch can be used to bride the vNIC to physical network cards. And the virtual switch can also be in kernel-sapce (e.g. Linux bridge~\cite{linux-bridge}), user-space (e.g. Snabb Switch~\cite{snabb}) and even both (e.g. Open vSwitch~\cite{ovs-2015}).  

The solutions of RDMA virtualization is including hardware-based and software-based. The basic solution is SR-IOV~\cite{sr-iov} in hardware-based virtualization of RDMA. Its virtual layer is in the hardware and are limited by hardware resources. In uniRDMA, the isolation of SR-IOV are utilized and the unscalable problems are solved by dynamic vRNIC mapping. 

In software virtualization, FreeFlow~\cite{kim2019freeflow} forwards all RDMA commands to the router and uniRDMA only forwards control commands. Its data path needs extra CPU to reduce the forward latency. HyV~\cite{pfefferle2015hybrid} and MasQ~\cite{he2020masq} are design for VMs, the similarity with uniRDMA is that all have achieved zero-copy and by-pass by mapping all resources. Even though, the implementation of mapping are different: mapping is done between two address space (the virtual layer and VM process). Moreover, HyV/MasQ backend is in kernel-space and uniRDMA backend is in user-space for more manageability and lightweight.