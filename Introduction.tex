\section{Introduction}
RDMA is a high-performance network,  with high throughput, low latency and low CPU load. Thus, RDMA is widely adopted in supercomputing for various applications,  such as artificial intelligence, and big data processing. 

Recently, most supercomputing is going cloud for efficiency and elasticity. To exploit RDMA’s high-performance in the cloud,  RDMA virtualization is necessary. Existing solutions for RDMA virtualization include software-based and  hardware-based. The SOTA software-based solutions are mainly about HyV, FreeFlow or MasQ~\cite{pfefferle2015hybrid}~\cite{kim2019freeflow}~\cite{he2020masq}. FreeFlow is  designed for containers and HyV/MasQ are proposed for virtual machines. The hardware-based solution is based on PCI pass-through for less overhead, like SR-IOV~\cite{sr-iov}. 

However, in practice, hybrid virtual environments are common for clouds. Detailedly, VMs, containers or others(e.g. containers in VMs) can be found in the same datacenter. The existing solutions are not suitable for hybrid virtual environments for the following reasons:

For software-based solutions, they are designed for specific virtual environments. Thus, in hybrid virtual environments, we should deploy multiple frameworks or extend one framework for another environment. If multiple frameworks co-exist in the same cluster, RDMA resources should be separate statically to avoid management conflict. This may cause the low utilization and higher complexity. Instead, we found that it is also limited to extend a framework for hybrid virtual environments. For FreeFlow,  the communication between applications and the virtual layer does not suit VMs and its forward overhead is unavoidable. For HyV or MasQ, compared to FreeFlow, their virtual layers are in kernel-space that brings new problems for containers, such as kernel exploitations, software inflexibility and strong hardware-awareness.

For hardware-based solutions, like SR-IOV~\cite{sr-iov},RDMA device resources are directly allocated to virtual machines or containers. Thus, the device utilization is static and inefficient. Moreover, RDMA networks are managed by physical switches or routers. Thus, network management is not scalable and isolated in clouds.

To address these problems, we propose a unified RDMA virtualization framework for hybrid virtual environment in clouds, namely uniRDMA, which also meets flexible management and high-performance. For centralized management, single distributed virtual layers are proposed for containers and VMs. The virtual layer is designed in user-space to maintain flexible management and reduce hardware-awareness, because it keeps away from kernel drivers of RDMA hardware. The virtual layer can be viewed as  multiple vRNICs (virtual RDMA network interface cards) and virtual RDMA switches. vRNIC is unified abstract encapsulation for applications in VMs or containers to achieve unified management . 

As the basic abstract unit of uniRDMA, vRNIC is virtualized and provided to RDMA applications. Each vRNIC is virtualized with complete attributes like physical RNIC, such as QP (Queue Pair) and DB (DoorBell registers) and all vRNICs are in userspace for flexible manageability and hiding kernel driver’s details. To utilize the high-performance of physical RNIC, vRNICs are mapped to the VF (the hardware-based virtual function) in RNIC respectively.

The driver of vRNIC is for RDMA applications in virtual environments. Note that VMs and containers are different visualizations in one server. Thus, the communication between driver and vRNIC devices are obviously different. To address it, the same communication protocols are proposed from applications to containers or VMs’ hypervisors. And a specific driver in guest OS is designed to transport applications’ commands in VMs. Moreover, for high-performance, we map the virtual RDMA resources between the vRNIC and application to achieve zero-copy and by-pass like native RDMA.

Virtual layer is responsible for RDMA devices management and virtual RDMA network. For RDMA device management,  under the limited VFs, we make dynamic vRNIC mapping in the virtual layer to get higher scalability. Besides, the virtual layer is software virtual switch for virtual RDMA network management, such as vRNIC address, routing rules.

Finally, we implement the prototype and evaluate it in different aspectsbenchmarks, such as throughput, latency, scalability, with and real-word applications. From the result, uniRDMA’s performance is close to native RDMA in hybrid virtual environment and the overhead is less than 5\% to hardware-based virtualization. uniRDMA also has high scalability and adapts to real-world RDMA applications in hybrid cloud environments. The main contributions in this paper are as follows:


\begin{itemize}
	\item Unified RDMA virtualization in hybrid virtual environments is firstly proposed in this paper, and it is stable for different kernels or RDMA devices. Besides, high performance and high manageability are maintained.  
	
	\item  By utilizing vhost-user and existing system calls, we realize the mapping of RDMA resources in userspace to achieve high-performance.  
	
	\item Unified framework is evaluated and the results proved that uniRDMA maintains high performance close to native RDMA.
\end{itemize}

