\section{Introduction}
RDMA (remote direct memory access) is a high-performance network,  with high throughput, low latency and low CPU load. Thus, RDMA is widely adopted in supercomputing for various applications,  such as artificial intelligence, and big data processing. 

Recently, migrating to cloud is a trend for supercomputing users. Different from traditional HPC environment, resource provisioning are done in the form of VMs or containers in clouds~\cite{hpc-cloud}. Moreover, hybrid virtual environments are common for clouds. In specific, VMs, containers or other form of virtualization (e.g. containers in VMs) can be found in the same datacenter or even on the same host machine. For hybrid virtual environments in clouds,  to exploit RDMA resources, RDMA virtualization needs to meets four following goals:

\begin{itemize}
	\item {\verb|Unification|}: Only single RDMA virtualization framework needs to be deployed in hybrid virtual environments and it provides centralized management. If not, there may cause the low resource utilization or higher management complexity.
	\item {\verb|High performance|}: Performance of virtual RDMA should be close to native RDMA in terms of throughput, latency, or CPU load. Meanwhile it should suit for large-scale virtual cluster.
	\item {\verb|High manageablility|}: Basic managment shoud be meet for the clouds, such as, performance isolation, virtual network management or portability.
	\item {\verb|Compatibility|}: RDMA virtualization framework should be clean and stable for different environments, and has minimal dependence of others, e.g. RDMA kernel driver.
\end{itemize}

However, neither of existing solutions can simultaneously achieve above goals. These solutions include software-based and hardware-based solutions. The software-based solutions are mainly about HyV~\cite{pfefferle2015hybrid}, FreeFlow~\cite{kim2019freeflow} or MasQ~\cite{he2020masq}. FreeFlow is  designed for containers and HyV/MasQ are proposed for virtual machines. All of them are designed for specific virtual environments. Moreover, in FreeFlow, there are apperant overhead in RDMA network beacause all RDMA commands do not bypass the router and kernel; for HyV /MasQ, their virtual layers are in kernel-space that brings new problems: the kernel's attack surface is larger due to lots of inserted code in kernel, managment development is inflexible in kernel programming, and the inserted modules are depenedent on hardware-specific RDMA kernel drivers.

The hardware-based solution is based on PCI pass-through for less overhead, like SR-IOV~\cite{sr-iov}. For hardware-based solutions (e.g. SR-IOV), RDMA device resources are directly allocated to virtual machines or containers. Thus, the device utilization is static and inefficient. Moreover, RDMA networks in clouds are still managed by physical switches or routers. Thus, virtual network management is not scalable and portable in large-scale clouds.

To address these problems, we propose a unified RDMA virtualization framework for hybrid virtual environment in clouds, namely uniRDMA, also with the design goals of flexible management and high-performance. 

As the basic abstract unit of uniRDMA, each vRNIC (virtual RDMA network interface card) is virtualized in user-space with basic RDMA attributes, such as QPs (Queue Pairs) and MRs(Memory Regions). To support VMs or containers unifiedly, vRNICs are the device of VMs and containers and a specific kernel driver is in guest OS. VMs and containers use the same communication protocal to vRNICs. Moreover, to optimize the performance, RDMA resources in vRNICs are mapped to applications in VMs or containers. Virtual layer tacks charge of vRNICs in each host server, including management RDMA devices, configuring vRNIC address and routing rules. 

Finally, we implement the prototype and evaluate it in different aspectsbenchmarks, such as throughput, latency, scalability, with and real-word applications. From the result, uniRDMA's performance is close to native RDMA in hybrid virtual environment and the overhead is less than 5\% to hardware-based virtualization. uniRDMA also has high scalability and adapts to real-world RDMA applications in hybrid cloud environments. The main contributions in this paper are as follows:

\begin{itemize}
\item We proposed vRNIC, which is a complete virtual RDMA device in host user-space for high flexibility and hardware independency. vRNIC is unified for both VMs and containers with specific driver. Meanwhile, the performance is optimized by mapping vRNIC to physical RNIC same as native RDMA.

\item We proposed a virtual layer for vRNICs, which is responsible for vRNICs' instantition and mapping to physical RNIC. Also, virtual RDMA network are configured in the virtual layer.

\item The whole unified framework, namely uniRDMA, is evaluated and the results proved that uniRDMA maintains high performance close to native RDMA.
\end{itemize}

The paper is organized as follows. Section 2 describes the backgroud of uniRDMA designs. Section 4 describes the vRNIC design in uniRDMA, and Section 5 introduces the design of virtual layer. Then, Section 6 reports the experimental results. Section 7 introduces related work. Finally, Section 8 concludes our work.
