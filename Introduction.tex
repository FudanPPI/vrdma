\section{Introduction}
Compared to tranditional computing, supercomputing has been widely adopted in different fields for high-performance, such as artificial intelligence, and large-scale data processing and engineering calculations. As the data dirves and the hardware develops, cloud computing is expanding everywhere for its high effiecncy and elasticity. Moreover, hybird virtual environments, which include both virtual machines and containers, is a trend in cloud due to combined advantages or historical reasons. As a result, lots of supercomputing has been in cloud, especially hybrid virtual environments, such as AWS HPC Cloud~\cite{aws-hpc}. 

As a high-performance network, RDMA is basic in supercomputing for each data-intensive application. For examples, MPI~\cite{mpi2004}, TensorFlow~\cite{abadi2016tensorflow}, Spark~\cite{spark-rdma}, and Hadoop~\cite{hadoop-rdma} all have supported RDMA. With hardware protocol stack and zero copy technologies, RNICs(physical RDMA network cards) can bypass the kernel to read/write remote memory regions in applications, without the aware of remote CPU. Therefore, RDMA has high throughput, low latency and low CPU load.

To expolit RDMA's high-performance, RDMA virtualization is necassery. Like network or other virtulization, adding a virtual layer and providing virtual RDMA interface to upper VMs or containers is important works in RDMA virtualization. Howerver, RDMA's hardware protocal stack and direct-access user memory make it hard to use traditional network virtual layer, such as virtual switch. Even though this problem has been atempped to solve in lots of different solutions, neither of them suit for hybrid virtual environments due to lack of network performance or unified management.

Exsiting solutions mainly about hardware-based and software-based. The representative hardware virtualization is SR-IOV~\cite{sr-iov}. Its virtual layer is located in the hardware. Although the isolation and high performance are maintained,  SR-IOV lacks portability and other manageability without software virtual layer. In software virtualization, existing solutions treat virtual machines and containers differently. For containers, FreeFlowl~\cite{kim2019freeflow} forwards all RDMA commands to the virtual layer, and that is ineffective because of losing RDMA's kernel by-pass. For virtual machines, HyV~\cite{pfefferle2015hybrid} ~\cite{pfefferle2014vverbs} avoids forwarding overhead by mapping RDMA resources, but lacks the management of virtual RDMA networks; although MasQ~\cite{he2020masq} makes up for this problem, its virtual layer is located in kernel space. Extending MasQ to the container environment will lose lightweight  management in user space for containers.

We proposes an unified RDMA virtualization framework for both containers and virtual machines, namely uniRDMA, which achieves high performance and high manageability in hybrid virtual environment. UniRDMA is mainly composed of single centralized uniRDMA virtual layer and general uniVerbs interfaces. All managements are concentrated in the user space virtual layer; the UniVerbs interface is general to the RDMA applications in virtual machines or containers.

There are mainly two challenges in the design of uniRDMA: First, virtual machines and containers are essentially different virtualization technologies. Virtual machines are under the management of hypervisor in kernel space, containers are isolted runtime mainly about user space. It is a challenge to build a centralized virtual layer for both containers and virtual machines; second, mapping all RDMA resources is the key idea to achive high performance. However, the existing solutions only implement the mapping operation in the same process for virtual machine. In this paper, the virtual layer belongs to another host process. So, it is also another challenge to map all RDMA resources.

To address the first challenge, uniRDMA separates the control and use of RDMA resources in virtulization, builds multiple vRNICs in single unified user space virtualization layer. Each vRNIC encapsulates virtual RDMA resources, and isolates with others by hardware virtualization. Moreover, through a common file-based shared memory queue, each vRNIC has a general interface for virtual machines and containers. For the second challenge,  at first, virtual RDMA resources in vRNICs are mapped to physical RNICs, and then shared memory are used to ensure RDMA resources in applications are mapped to vRNICs in the virtual layer.

We implements the prototype of uniRDMA and evaluate uniRDMA against with hardware virtualization, software virtualization FreeFlow, and native RDMA in different benchmarks, such as throughput, latency, scalability, and real-word applications. From the result, uniRDMA's performance is close to native RDMA in both virtual machine and container environments, and is significantly better than FreeFlow. The throughput can reach up to 6 times that of FreeFlow, and the latency can reach down to 40\% of FreeFlow.uniRDMA also has high scalability and adapts to real-world RDMA applications in hybrid cloud environments.The main contributions in this paper are as follows:

\begin{itemize}
\item Unified RDMA virtulization in hybrid virtual environments is firstly proposed in this paper and uniRDMA is general RDMA virtualization framework,  while maintaining high performance and high manageability.

\item uniRDMA are evaluated and the results proved that uniRDMA maintains high performance close to native RDMA.
\end{itemize}
